{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mascj670/css-syntax-selectors-master/blob/main/gpt_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB8caKSxvRYO"
      },
      "source": [
        "# Intro to GPT-3 #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1eMc_jivRYQ",
        "outputId": "9176788e-fb66-4544-b229-c6f60bb02230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "#guide https://beta.openai.com/docs/developer-quickstart/python-bindings\n",
        "#make sure you download pip install openai (pip3 if you have multiple versions of python installed on your computer)\n",
        "\n",
        "# playground https://beta.openai.com/playground/p/8P6JA6XEx74NTvcRUngWKEYW\n",
        "!pip install openai\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00GTkFW_vRYR"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"INSERT_API_KEY_HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w777sm14vRYS"
      },
      "outputs": [],
      "source": [
        "text = 'what is machine learning?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFLXMhvwvRYS"
      },
      "outputs": [],
      "source": [
        "# # https://beta.openai.com/pricing\n",
        "# # davinci engine is their most powerful model\n",
        "response = openai.Completion.create(engine=\"davinci\", prompt=text, max_tokens=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDngtflyvRYS",
        "outputId": "f3c6e89e-6b43-4989-a84d-5ca985ddeae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-7x3jMYV5bwjeP3vATzhMDihumF0lv\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1694310048,\n",
            "  \"model\": \"davinci\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \" one answer: machine learning is a decision-makes process by machines\\u2019.\\n\\nwhat tools\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"length\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 5,\n",
            "    \"completion_tokens\": 20,\n",
            "    \"total_tokens\": 25\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbFP2V-uvRYS",
        "outputId": "7d81c85a-2c7e-41d6-eda7-2ec69b0999f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " one answer: machine learning is a decision-makes process by machines’.\n",
            "\n",
            "what tools\n"
          ]
        }
      ],
      "source": [
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yE8mQ67nvRYS"
      },
      "outputs": [],
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-001\",\n",
        "  prompt=\"Explain machine learning in a short sentence.\",\n",
        "  temperature=0.4, #randomness\n",
        "  max_tokens=64, #charaters in response\n",
        "  top_p=1, #controls diversity\n",
        "  frequency_penalty=0, #decrease repetition\n",
        "  presence_penalty=0 #increase likelihood to talk about new topic\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ormsGijGvRYT",
        "outputId": "e591ba6b-58fe-4320-839c-4c3e36931423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Machine learning is a method of teaching computers to learn from data, without being explicitly programmed.\n"
          ]
        }
      ],
      "source": [
        "result = response.choices[0].text\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or3ahLgjvRYT"
      },
      "source": [
        "# Let's try some new examples #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw5CnRBDvRYT"
      },
      "source": [
        "What is \"prompting?\"\n",
        "\n",
        "In GPT-3's API, a 'prompt' is a parameter that is provided to the API so that it is able to identify the context of the problem to be solved. It can be referred to as \"prompt engineering.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZffzYrBvRYT"
      },
      "source": [
        "### PROMPT ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL4XMINQvRYU"
      },
      "source": [
        "I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \"Unknown\".\n",
        "\n",
        "Q: What is human life expectancy in the United States?\n",
        "A: Human life expectancy in the United States is 78 years.\n",
        "\n",
        "Q: Who was president of the United States in 1955?\n",
        "A: Dwight D. Eisenhower was president of the United States in 1955.\n",
        "\n",
        "Q: Which party did he belong to?\n",
        "A: He belonged to the Republican Party.\n",
        "\n",
        "Q: What is the square root of banana?\n",
        "A: Unknown\n",
        "\n",
        "Q: How does a telescope work?\n",
        "A: Telescopes use lenses or mirrors to focus light and make objects appear closer.\n",
        "\n",
        "Q: Where were the 1992 Olympics held?\n",
        "A: The 1992 Olympics were held in Barcelona, Spain.\n",
        "\n",
        "Q: How many squigs are in a bonk?\n",
        "A: Unknown\n",
        "\n",
        "Q: Where is the Valley of Kings?\n",
        "A:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAnhFQXMvRYU"
      },
      "outputs": [],
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Where is the Valley of Kings?\\nA:\",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgwHyBSpvRYU",
        "outputId": "6e8b3056-7168-4eac-e196-69365b1922e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Valley of Kings is located in Egypt.\n"
          ]
        }
      ],
      "source": [
        "result = response.choices[0].text\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU9ItvYqvRYU"
      },
      "source": [
        "### PROMPT ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90XDFgDDvRYV"
      },
      "source": [
        "The following is a list of companies and the categories they fall into:\n",
        "\n",
        "Apple, Facebook, Fedex\n",
        "\n",
        "Apple\n",
        "Category:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcX-F0xHvRYV"
      },
      "outputs": [],
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"The following is a list of companies and the categories they fall into:\\n\\nApple, Facebook, Fedex\\n\\nApple\\nCategory:\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KrZhymKovRYV",
        "outputId": "468e3832-8896-42be-d833-7fd8ce543dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Technology\n",
            "\n",
            "Facebook\n",
            "Category: Social Media\n",
            "\n",
            "Fedex\n",
            "Category: Delivery\n"
          ]
        }
      ],
      "source": [
        "result = response.choices[0].text\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM_oNU5RvRYV"
      },
      "source": [
        "### PROMPT ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuK0wAi6vRYV"
      },
      "source": [
        "Convert movie titles into emoji.\n",
        "\n",
        "Back to the Future: 👨👴🚗🕒\n",
        "Batman: 🤵🦇\n",
        "Transformers: 🚗🤖\n",
        "Star Wars:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05FVnxPBvRYV"
      },
      "outputs": [],
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Convert movie titles into emoji.\\n\\nBack to the Future: 👨👴🚗🕒 \\nBatman: 🤵🦇 \\nTransformers: 🚗🤖 \\nStar Wars:\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7vmMiFivRYW",
        "outputId": "3af62b29-c7d0-4983-ac6e-77c10f215787",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 🌟🚀🛰\n"
          ]
        }
      ],
      "source": [
        "result = response.choices[0].text\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "175h59o2vRYW"
      },
      "source": [
        "### PROMPT ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRdnZTb5vRYW"
      },
      "source": [
        "Classify the sentiment in these tweets:\n",
        "\n",
        "1. \"I can't stand homework\"\n",
        "2. \"This sucks. I'm bored 😠\"\n",
        "3. \"I can't wait for Halloween!!!\"\n",
        "4. \"My cat is adorable ❤️❤️\"\n",
        "5. \"I hate chocolate\"\n",
        "\n",
        "Tweet sentiment ratings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvrvZwijvRYW"
      },
      "outputs": [],
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Classify the sentiment in these tweets:\\n\\n1. \\\"I can't stand homework\\\"\\n2. \\\"This sucks. I'm bored 😠\\\"\\n3. \\\"I can't wait for Halloween!!!\\\"\\n4. \\\"My cat is adorable ❤️❤️\\\"\\n5. \\\"I hate chocolate\\\"\\n\\nTweet sentiment ratings:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymNs-HYEvRYW",
        "outputId": "62ba7f64-9d8f-464f-825c-bbb71e1fff97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Negative\n",
            "2. Negative\n",
            "3. Positive\n",
            "4. Positive\n",
            "5. Negative\n"
          ]
        }
      ],
      "source": [
        "result = response.choices[0].text\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb3IYnzEvRYX"
      },
      "source": [
        "### PROMPT ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIWzr6u0vRYX"
      },
      "source": [
        "The CSS code for a color like a blue sky at dusk:\n",
        "\n",
        "background-color: #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f8XAm13vRYX"
      },
      "outputs": [],
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"The CSS code for a color like a blue sky at dusk:\\n\\nbackground-color: #\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\";\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNFzUTKuvRYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e3a736-1f59-4844-f1ad-276dfc78a35b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "003366\n"
          ]
        }
      ],
      "source": [
        "result = response.choices[0].text\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6jvwlQUvRYX"
      },
      "source": [
        "### PROMPT ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoJqrhGRvRYX"
      },
      "source": [
        "Write a recipe based on these ingredients and instructions:\n",
        "\n",
        "Frito Pie\n",
        "\n",
        "Ingredients:\n",
        "Fritos\n",
        "Chili\n",
        "Shredded cheddar cheese\n",
        "Sweet white or red onions, diced small\n",
        "Sour cream\n",
        "\n",
        "Instructions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9AO58g3vRYX"
      },
      "outputs": [],
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"Write a recipe based on these ingredients and instructions:\\n\\nFrito Pie\\n\\nIngredients:\\nFritos\\nChili\\nShredded cheddar cheese\\nSweet white or red onions, diced small\\nSour cream\\n\\nInstructions:\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=120,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6-z0r2uvRYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4804e0c5-8edb-4c3f-b643-90b028a6f6b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Preheat oven to 350 degrees F.\n",
            "2. Spread a layer of Fritos in the bottom of a 9x13-inch baking dish.\n",
            "3. Top with chili, onions, and cheese.\n",
            "4. Repeat layering until all ingredients are used.\n",
            "5. Bake for 20 minutes or until cheese is melted and bubbly.\n",
            "6. Let cool for 5 minutes before serving.\n",
            "7. Serve with sour cream.\n"
          ]
        }
      ],
      "source": [
        "result = response.choices[0].text\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAzhc8f2vRYX"
      },
      "source": [
        "### Chat Gpt ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhgRoXeNvRYY"
      },
      "outputs": [],
      "source": [
        "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
        "# !pip install --upgrade openai\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MpYozCWvRYY",
        "outputId": "6f32f146-4b07-486b-a5c9-df1a64c7dc3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"role\": \"assistant\",\n",
            "  \"content\": \"The World Series in 2020 was played at Globe Life Field in Arlington, Texas.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "result = response.choices[0].message\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
        "# !pip install --upgrade openai\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a sassy movie expert\"},\n",
        "        {\"role\": \"user\", \"content\": \"What's the saddest rom-com of all time?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Clearly 'Eternal Sunshine of the Spotless Mind'. It's more about the concept of love.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What's the best action movie ever?\"}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "1wR-sJctwLb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = response.choices[0].message\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8w2ZX86wMrD",
        "outputId": "d656abb9-d8a8-4a4d-bd87-46b1ab73e94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"role\": \"assistant\",\n",
            "  \"content\": \"Well, that's a tough one because opinions on what makes an action movie \\\"the best\\\" can vary. But for my money, I'd have to go with 'Die Hard'. It's the perfect blend of adrenaline-pumping action, witty one-liners, and a badass protagonist in John McClane. Yippee-ki-yay!\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjCMBZGXvRYY"
      },
      "source": [
        "### DALL-E ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTmaEg6PvRYZ"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "response = openai.Image.create(\n",
        "  prompt=\"A tiny green monster with one eye sitting on top of a machine that sits on top of planet earth, 3D style \",\n",
        "  n=1,\n",
        "  size=\"1024x1024\"\n",
        ")\n",
        "image_url = response['data'][0]['url']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwvFiPtqvRYZ",
        "outputId": "4e11b27c-0023-4a42-85f9-14fe8d8b8fbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://oaidalleapiprodscus.blob.core.windows.net/private/org-tRqvc2Il3iJ8osbAtkuYtnE7/user-AyrjxnIY85bzcScNvXPp4nbL/img-MjbTVxHlHpCCCWJ1trgwrrU6.png?st=2023-09-10T00%3A45%3A44Z&se=2023-09-10T02%3A45%3A44Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-09T18%3A33%3A58Z&ske=2023-09-10T18%3A33%3A58Z&sks=b&skv=2021-08-06&sig=57k6ANZihn2T5/aVSrrW8ksR43P9C4TsqZ7kLDAm9Jk%3D\n"
          ]
        }
      ],
      "source": [
        "print(image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4bHuGY2vRYZ",
        "outputId": "629290eb-0d11-4599-b0a4-574b654bdf99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-tRqvc2Il3iJ8osbAtkuYtnE7/user-AyrjxnIY85bzcScNvXPp4nbL/img-MjbTVxHlHpCCCWJ1trgwrrU6.png?st=2023-09-10T00%3A45%3A44Z&se=2023-09-10T02%3A45%3A44Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-09-09T18%3A33%3A58Z&ske=2023-09-10T18%3A33%3A58Z&sks=b&skv=2021-08-06&sig=57k6ANZihn2T5/aVSrrW8ksR43P9C4TsqZ7kLDAm9Jk%3D\" width=\"500\" height=\"500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "Image(url= image_url, width=500, height=500)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}